{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aya-se/advanced-machine-learning-2022/blob/main/aml2022_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z-I39fBi1MD"
      },
      "source": [
        "# Advanced Machine Learning (2022) Final Report Assignment\n",
        "\n",
        "Answer Questions 1 to 4 (either in Japanese or English). Submit a report in either PDF (.pdf) or JupyterNotebook (.ipynb) format.\n",
        "\n",
        "## Question 1 (50 points)\n",
        "\n",
        "Consider a convolutional neural network (CNN) that predicts a label $\\hat{y} \\in \\{0, 1\\}$ for a given sentence $\\boldsymbol{X} \\in \\mathbb{R}^{d \\times T}$. Here, a sentence is represented by a matrix $\\boldsymbol{X} = (\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\dots, \\boldsymbol{x}_T)$ consisting of a concatenation of $T$ word embeddings, $\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\dots, \\boldsymbol{x}_T \\in \\mathbb{R}^d$, where $d$ is the size of word embeddings, and $T$ is the number of words in the sentence.\n",
        "\n",
        "These equations define the whole architecture of the CNN.\n",
        "\n",
        "\\begin{align}\n",
        "\\hat{y} &= \\begin{cases}\n",
        "1 & (0.5 < p) \\\\\n",
        "0 & (p \\leq 0.5)\n",
        "\\end{cases} \\\\\n",
        "p &= \\sigma(\\boldsymbol{v}^\\top \\boldsymbol{s}) \\\\\n",
        "\\boldsymbol{s} &= \\max(\\boldsymbol{c}_1, \\dots, \\boldsymbol{c}_{T-\\delta+1}) \\\\\n",
        "\\boldsymbol{c}_t &= {\\rm ReLU}(\\boldsymbol{W} \\boldsymbol{x}_{t:t+\\delta-1} + \\boldsymbol{b}) & (\\forall t \\in \\{1, \\dots, T-\\delta+1\\}) \\\\\n",
        "\\boldsymbol{x}_{t:t+\\delta-1} &= \\boldsymbol{x}_{t} \\oplus \\boldsymbol{x}_{t+1} \\oplus \\dots \\oplus \\boldsymbol{x}_{t+\\delta-1}\n",
        "\\end{align}\n",
        "\n",
        "Here:\n",
        "\n",
        "+ $\\boldsymbol{W} \\in \\mathbb{R}^{m \\times \\delta d}$, $\\boldsymbol{b} \\in \\mathbb{R}^m, \\boldsymbol{v} \\in \\mathbb{R}^m$ are the model parameters;\n",
        "+ $m$ denotes the number of output channels of the CNN;\n",
        "+ $\\delta$ denotes the width (kernel size) of the convolution;\n",
        "+ $\\sigma(\\cdot)$ denotes the standard sigmoid function;\n",
        "+ $\\max(\\cdot)$ presents the max pooling operation;\n",
        "+ ${\\rm ReLU}(\\cdot)$ denotes the ReLU activation function;\n",
        "+ $\\oplus$ presents a concatenation of vectors.\n",
        "\n",
        "Setting the hyperparameters $d=3, m=2, \\delta=2$, we initialize the model parameters as follows.\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{W} &= \\begin{pmatrix}\n",
        "-3 & -2 & -1 & -1 & -2 & -3 \\\\\n",
        "3 & 2 & 3 & 2 & 3 & 2\n",
        "\\end{pmatrix} \\\\\n",
        "\\boldsymbol{b} &= \\begin{pmatrix}\n",
        "-0.2 \\\\ 0.1\n",
        "\\end{pmatrix} \\\\\n",
        "\\boldsymbol{v} &= \\begin{pmatrix}\n",
        "-1 \\\\ 2\n",
        "\\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Suppose that we give a negative ($y=0$) training instance with the sentence ($T = 5$),\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{X} &= \\begin{pmatrix}\n",
        "-0.3 & 0 & 0.1 & 0 & 0 \\\\\n",
        "-0.2 & -0.1 & 0 & 0.1 & 0 \\\\\n",
        "-0.1 & -0.2 & 0.1 & 0 & 0.1\n",
        "\\end{pmatrix} ,\n",
        "\\end{align}\n",
        "to the CNN model, and answer the following questions.\n",
        "\n",
        "**(1)** Find the value of the vector $\\boldsymbol{x}_{3:4}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要ライブラリのインポート\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-3., -2., -1., -1., -2., -3.],\n",
              "        [ 3.,  2.,  3.,  2.,  3.,  2.]]),\n",
              " array([[-0.2],\n",
              "        [ 0.1]]),\n",
              " array([[-1.],\n",
              "        [ 2.]]),\n",
              " array([[-0.3,  0. ,  0.1,  0. ,  0. ],\n",
              "        [-0.2, -0.1,  0. ,  0.1,  0. ],\n",
              "        [-0.1, -0.2,  0.1,  0. ,  0.1]]),\n",
              " 3,\n",
              " 2,\n",
              " 2)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 各種変数の準備\n",
        "W = np.array([[-3.0, -2.0, -1.0, -1.0, -2.0, -3.0], [3.0, 2.0, 3.0, 2.0, 3.0, 2.0]])\n",
        "b = np.array([[-0.2], [0.1]])\n",
        "v = np.array([[-1.0], [2.0]])\n",
        "X = np.array([[-0.3, 0, 0.1, 0, 0], [-0.2, -0.1, 0, 0.1, 0], [-0.1, -0.2, 0.1, 0, 0.1]])\n",
        "W, b, v, X, d, m, delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uec36GNAyNdz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.1, 0. , 0.1, 0. , 0.1, 0. ])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x_{3:4}\n",
        "np.concatenate([X[:, 2], X[:, 3]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XCf-KoPyOfp"
      },
      "source": [
        "**(2)** Find the values of the hidden vectors $\\boldsymbol{c}_1, \\boldsymbol{c}_2, \\boldsymbol{c}_3, \\boldsymbol{c}_4$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "sgxmns3JyQgB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[2.],\n",
              "        [0.]]),\n",
              " array([[0.],\n",
              "        [0.]]),\n",
              " array([[0.],\n",
              "        [1.]]),\n",
              " array([[0. ],\n",
              "        [0.5]]))"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# コンテキストベクトルc_tの計算\n",
        "def c(t) :\n",
        "    val = (W @ np.concatenate([X[:, t], X[:, t+1]])).reshape(2, 1) + b\n",
        "    return np.maximum(0, val)\n",
        "\n",
        "c(0), c(1), c(2), c(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVFqVPWPyQ58"
      },
      "source": [
        "**(3)** Find the value of the vector $\\boldsymbol{s}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Vt3UQqqAyTVj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.],\n",
              "       [1.]])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = np.max(np.hstack([c(0), c(1), c(2), c(3)]), axis=1)\n",
        "s.reshape(2, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt26e_TSyT6W"
      },
      "source": [
        "**(4)** Find the value of $p$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "U4g6j4L3y635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5000000000000002"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "p = sigmoid(v.T @ s)[0]\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUh6ZlAqyWRE"
      },
      "source": [
        "**(5)** Write the formula of the binary cross-entropy loss between the correct label $y$ and the probability estimate $p$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "QdCPWs4UyV9b"
      },
      "outputs": [],
      "source": [
        "# 注：p=0,1の時の処理は省略する\n",
        "def BCE(y, p):\n",
        "    return -(y * np.log(p) + (1-y) * np.log(1-p)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9WQToWfyYuj"
      },
      "source": [
        "**(6)** Compute the loss value by using the formula of (5) for the training instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "LsFTKdK3zpYC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6931471805599457"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = BCE(0, p)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b03t2amzpz5"
      },
      "source": [
        "**(7)** Compute the gradient of the loss function with respect to $\\boldsymbol{v}$ for the training instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "負例の場合の勾配は、$\\displaystyle\\frac{\\partial BCE(p)}{\\partial v}=\\frac{1}{1-p}\\cdot p(1-p)\\cdot s$と求まることから、以下のように計算できる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Oa0xGZNgz7bY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1. ],\n",
              "       [0.5]])"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grad_v = 1/(1-p) * p * (1-p) * s\n",
        "grad_v.reshape(2, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTt2o7hKz7zD"
      },
      "source": [
        "**(8)** Compute the gradients of the loss function with respect to $\\boldsymbol{W}$ for the training instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(7)と同様にして誤差逆伝播法で、勾配を計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "0mz0yeWF0PIy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.3 -0.2 -0.1  0.  -0.1 -0.2]\n",
            " [ 0.1  0.   0.1  0.   0.1  0. ]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 0.15,  0.1 ,  0.05, -0.  ,  0.05,  0.1 ],\n",
              "       [ 0.1 ,  0.  ,  0.1 ,  0.  ,  0.1 ,  0.  ]])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grad_W = 1/(1-p) * p * (1-p) * v * np.array([np.concatenate([X[:, 0], X[:, 0+1]]), np.concatenate([X[:, 2], X[:, 2+1]])])\n",
        "grad_W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPWwlW4F0P0i"
      },
      "source": [
        "## Question 2 (20 points)\n",
        "\n",
        "Give names of two datasets that can be used to evaluate the quality of word embeddings, and explain the datasets with the following perspectives.\n",
        "\n",
        "+ Brief explanation of the task for the evaluation.\n",
        "+ Statistics of the dataset (e.g., the number of instances)\n",
        "+ Measure(s) for evaluating the quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdNBHor63biK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYrvAyBW3TxD"
      },
      "source": [
        "## Question 3 (20 points)\n",
        "\n",
        "Explain two reasons why Transformers are superior to Recurrent Neural Network\n",
        "(RNN) in sequence-to-sequence tasks such as Machine Translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqfAdU713cYa"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYxI86gA3dGs"
      },
      "source": [
        "## Question 4 (10 points)\n",
        "\n",
        "Implement the code for using a pre-trained **language** model. Show the code and its output as well as the following information:\n",
        "\n",
        "+ The detail of the pre-trained language model, for example,\n",
        "    + https://huggingface.co/EleutherAI/gpt-j-6B\n",
        "    + https://huggingface.co/rinna/japanese-gpt-1b\n",
        "    + https://huggingface.co/facebook/blenderbot-400M-distill\n",
        "+ The task addressed by the model (e.g., \"text generation\", \"summarization\", \"chatbot\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCaAqhtCGC2I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "aml2022_report.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
